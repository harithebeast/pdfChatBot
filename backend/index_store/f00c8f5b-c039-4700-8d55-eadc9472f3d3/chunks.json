["Previous AI Projects \nHarivarsan K. \n \n1. LipNet (Lip Reading using Deep Learning) \n\u2022 \nDeveloped a deep learning model capable of recognizing spoken words through visual lip \nmovements. \n\u2022 \nImplemented a combination of spatiotemporal Convolutional Neural Networks (CNNs) and \nRecurrent Neural Networks (RNNs). \n\u2022 \nTrained and tested the model on the GRID dataset, achieving sentence-level prediction with \nhigh accuracy. \n \n2. \u201cAll You Need Is Attention\u201d \u2013 Transformer Architecture Reproduction \n\u2022 \nR", "eproduced the original Transformer model based on Vaswani et al. (2017). \n\u2022 \nBuilt from scratch using PyTorch, focusing on Multi-Head Attention, Positional Encoding, and \nLayer Normalization. \n\u2022 \nEvaluated model on translation tasks and compared its efficiency against traditional RNN-\nbased models. \n \n3. Doctoral-Level Fine-Tuning of LLMs \n\u2022 \nFine-tuned large language models (LLMs) such as GPT and LLaMA using techniques like LoRA \nand PEFT. \n\u2022 \nConducted experiments on domain-specific datasets t", "o evaluate task-specific performance \nimprovements. \n\u2022 \nFocused on optimizing training efficiency while maintaining high model accuracy and \nstability. \n \nSummary \nThese projects have significantly strengthened my skills in deep learning, computer vision, and \nnatural language processing. I\u2019ve gained practical experience in working with state-of-the-art \narchitectures, fine-tuning large models, and conducting impactful AI research. \n \n"]